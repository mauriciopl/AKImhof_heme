{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to run the Dock ensembl macro step-by-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 False\n",
      "2 False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There were too many steps to code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fisrt copy the ligand file to the folder\n",
    "# rename the ligand file to <receptorname>_ligand.pdb\n",
    "# rename the receptor file to <receptorname>_receptor.xxx\n",
    "# copy the macro template to the current directory to change the Macrotarget line freely\n",
    "# run the steps as in the macro dock_runensemble\n",
    "## run 10 times:\n",
    "## copy \n",
    "import yasara as y\n",
    "from os.path import isfile\n",
    "\n",
    "y.info.mode='txt'\n",
    "\n",
    "def yasara_docking(my_receptor,            my_method='VINA',    my_ligand='.pdb', \n",
    "                   num_runs=1,             my_clusterrmsd=5.0,  my_resultfile=\"haha_00\",  \n",
    "                   my_tmpfileid=None,      my_gridparlist=None, my_dockparlist=None, \n",
    "                   my_setuponly=None):\n",
    "    \"\"\"Fill documentation\"\"\"\n",
    "    print(\"Docking experiment:\", my_receptor)  \n",
    "    y.Clear()\n",
    "    a = y.LoadPDB(my_receptor)\n",
    "    print(\"receptor = \", a)\n",
    "    b = y.LoadPDB(my_ligand)\n",
    "    print(\"receptor = \", b)  \n",
    "    y.ForceField(\"AMBER03\")\n",
    "    y.FixObj(b[0])\n",
    "    #file:///home/imhof_team/Downloads/yasara/doc/Commands.html#HeadTarget\n",
    "    y.ExperimentDocking(method=my_method,             ligandobj=b[0], \\\n",
    "                        receptorobj=a[0],      runs=num_runs,\\\n",
    "                        clusterrmsd=my_clusterrmsd,   resultfile=my_resultfile, \\\n",
    "                        tmpfileid=my_tmpfileid,       gridparlist=my_gridparlist, \\\n",
    "                        dockparlist=my_dockparlist,   setuponly=my_setuponly)\n",
    "    y.Experiment(\"On\")\n",
    "    #y.LogAs(\"dummy.txt\")\n",
    "    y.Wait(\"ExpEnd\")\n",
    "    y.AddObj(\"all\")\n",
    "    y.SaveSce(\"mysce\")\n",
    "    y.RemoveObj(\"all\")\n",
    "    y.AddObj(\"1 2\")\n",
    "    ligsel = \"Obj \"+str(b[0])+\" Segment C001\"\n",
    "    recsel= \"Obj 1\"\n",
    "    print(\"Bfactor\", y.BFactorAtom(\"Obj Ligand \"+str(b[0])+\" Segment C001\"))\n",
    "    print(\"PropAtom\",y.PropAtom(\"Obj \"+str(b[0])+\" Segment C001\"))\n",
    "    print(\"Res List\", y.ListRes(\"Obj 1 with distance<4.0 from \"+ ligsel, format='RESNAME MOLNAME RESNUM'))\n",
    "    y.ListRes(\"Obj 1\" , format='RESNAME MOLNAME RESNUM')\n",
    "    print(\"Exp ended\")\n",
    "    return True\n",
    "\n",
    "print(\"1\", isfile(\"receptor.pdb\"))\n",
    "print(\"2\", isfile(\"ligand.pdb\"))\n",
    "# yasara_docking('receptor.pdb', my_ligand='ligand.pdb', num_runs=1)\n",
    "# y.ApplyMacro\n",
    "# file:///home/imhof_team/Downloads/yasara/doc/ApplyMacro.html#HeadTarget\n",
    "\n",
    "\"There were too many steps to code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saved in case I want to parse the html'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from html.parser import HTMLParser\n",
    "\n",
    "\n",
    "class MyHTMLParser(HTMLParser):\n",
    "    def __init__(self):\n",
    "        HTMLParser.__init__(self)\n",
    "        self.reset()\n",
    "        self.open_tags = []\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        self.open_tags+= [tag]\n",
    "        #print(\"Encountered a start tag:\", tag)\n",
    "\n",
    "    def handle_endtag(self, tag):\n",
    "        a = self.open_tags.pop()\n",
    "        while a != tag:\n",
    "            print(\"invalid tag order\")\n",
    "            print(tag)\n",
    "            print(a)\n",
    "            a = self.open_tags.pop()\n",
    "        #print(\"Encountered an end tag :\", tag)\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        print(\"data found inside tags\", \"->\".join(self.open_tags))\n",
    "        #print(\"Encountered some data  :\", data)\n",
    "\n",
    "parser = MyHTMLParser()\n",
    "\n",
    "with open(\"IL-1A(271)/IL-1A(271).html\") as f:\n",
    "    html = f.read()\n",
    "\n",
    "parser.feed(html)\"\"\"\n",
    "\n",
    "\"Saved in case I want to parse the html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to use parsers to read pdb/cif files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_letter_sequence(filename):\n",
    "    if filename[-3:].upper() == \"PDB\":\n",
    "        parser = bpdb.MMCIFParser()\n",
    "    elif filename[-3:].upper() == \"CIF\":\n",
    "        parser = bpdb.MMCIFParser()\n",
    "    else:\n",
    "        raise \"Error: unexpected file type\"\n",
    "    structure = parser.get_structure('file', filename)\n",
    "    print(\"seq\", parser.get_sequence())\n",
    "    ppb = bpdb.PPBuilder() # PolypeptideBuilder\n",
    "    for pp in ppb.build_peptides(structure):\n",
    "        print (pp.get_sequence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequences for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = \"\" # \n",
    "seq = \"\" # \n",
    "seq = \"\" # \n",
    "seq = \"MSENKNSEAEDVFEFLDSLPEAKNGGKMVNTDVKGSQEGVKGGSNSVAGKTGNDGKKGDD\\\n",
    "DIFEFLEELEKSNLSLTDKKGVEKKAPSESVNNKAQDEKVEESKENKNSEQDAHGKEKEP\\\n",
    "QQQEKEEEEEEEEEEEEEEEETPLHDPIASISNWWSSSGSAKVSSIWNKTAEQASQIKNR\\\n",
    "LAQEQLDLTSKINTSTITEIARNLQKIVVGETEEVLRIHLVHDLVNYPSLQYNIESKFDQ\\\n",
    "VLSSQVEGGIRIFVDEWGHPNNNGITPVEKKPSVADGELGNSKKKLQFNLFDGKVTDGEK\\\n",
    "LAFANLENAVKLFNTAHEEYQKQQKEADATPDDDRSSISSNSNKISDLFISILPIAIPQK\\\n",
    "QKDADGDFQVTDSNTPGNFNFTLVLKDITNDITTITRSQGFPVKWVNWLEGSVEKTGSTA\\\n",
    "SEERNKSYDQKKQKESEDEDEDDEIIDPSEWVKEWIEDGLSLSFGVMAQNYVIDRMGL\" # MTC1(478)\n",
    "\n",
    "seq = \"MTKLHFDTAEPVKITLPNGLTYEQPTGLFINNKFMKAQDGKTYPVEDPSTENTVCEVSSA\\\n",
    "TTEDVEYAIECADRAFHDTEWATQDPRERGRLLSKLADELESQIDLVSSIEALDNGKTLA\\\n",
    "LARGDVTIAINCLRDAAAYADKVNGRTINTGDGYMNFTTLEPIGVCGQIIPWNFPIMMLA\\\n",
    "WKIAPALAMGNVCILKPAAVTPLNALYFASLCKKVGIPAGVVNIVPGPGRTVGAALTNDP\\\n",
    "RIRKLAFTGSTEVGKSVAVDSSESNLKKITLELGGKSAHLVFDDANIKKTLPNLVNGIFK\\\n",
    "NAGQICSSGSRIYVQEGIYDELLAAFKAYLETEIKVGNPFDKANFQGAITNRQQFDTIMN\\\n",
    "YIDIGKKEGAKILTGGEKVGDKGYFIRPTVFYDVNEDMRIVKEEIFGPVVTVAKFKTLEE\\\n",
    "GVEMANSSEFGLGSGIETESLSTGLKVAKMLKAGTVWINTYNDFDSRVPFGGVKQSGYGR\\\n",
    "EMGEEVYHAYTEVKAVRIKL\" # ALD6(500)\n",
    "\n",
    "seq = \"MKFSAGAVLSWSSLLLASSVFAQQEAVAPEDSAVVKLATDSFNEYIQSHDLVLAEFFAPW\\\n",
    "CGHCKNMAPEYVKAAETLVEKNITLAQIDCTENQDLCMEHNIPGFPSLKIFKNSDVNNSI\\\n",
    "DYEGPRTAEAIVQFMIKQSQPAVAVVADLPAYLANETFVTPVIVQSGKIDADFNATFYSM\\\n",
    "ANKHFNDYDFVSAENADDDFKLSIYLPSAMDEPVVYNGKKADIADADVFEKWLQVEALPY\\\n",
    "FGEIDGSVFAQYVESGLPLGYLFYNDEEELEEYKPLFTELAKKNRGLMNFVSIDARKFGR\\\n",
    "HAGNLNMKEQFPLFAIHDMTEDLKYGLPQLSEEAFDELSDKIVLESKAIESLVKDFLKGD\\\n",
    "ASPIVKSQEIFENQDSSVFQLVGKNHDEIVNDPKKDVLVLYYAPWCGHCKRLAPTYQELA\\\n",
    "DTYANATSDVLIAKLDHTENDVRGVVIEGYPTIVLYPGGKKSESVVYQGSRSLDSLFDFI\\\n",
    "KENGHFDVDGKALYEEAQEKAAEEADADAELADEEDAIHDEL\" # PDI1(522)\n",
    "\n",
    "seq = \"MSEKFPPLEDQNIDFTPNDKKDDDTDFLKREAEILGDEFKTEQDDILETEASPAKDDDEI\\\n",
    "RDFEEQFPDINSANGAVSSDQNGSATVSSGNDNGEADDDFSTFEGANQSTESVKEDRSEV\\\n",
    "VDQWKQRRAVEIHEKDLKDEELKKELQDEAIKHIDDFYDSYNKKKEQQLEDAAKEAEAFL\\\n",
    "KKRDEFFGQDNTTWDRALQLINQDDADIIGGRDRSKLKEILLRLKGNAKAPGA\" # CLC1(233)\n",
    "\n",
    "seq = \"MSSAITALTPNQVNDELNKMQAFIRKEAEEKAKEIQLKADQEYEIEKTNIVRNETNNIDG\\\n",
    "NFKSKLKKAMLSQQITKSTIANKMRLKVLSAREQSLDGIFEETKEKLSGIANNRDEYKPI\\\n",
    "LQSLIVEALLKLLEPKAIVKALERDVDLIESMKDDIMREYGEKAQRAPLEEIVISNDYLN\\\n",
    "KDLVSGGVVVSNASDKIEINNTLEERLKLLSEEALPAIRLELYGPSKTRKFFD\" # VMA4(233) !!!\n",
    "\n",
    "seq = \"MDSEVAALVIDNGSGMCKAGFAGDDAPRAVFPSIVGRPRHQGIMVGMGQKDSYVGDEAQS\\\n",
    "KRGILTLRYPIEHGIVTNWDDMEKIWHHTFYNELRVAPEEHPVLLTEAPMNPKSNREKMT\\\n",
    "QIMFETFNVPAFYVSIQAVLSLYSSGRTTGIVLDSGDGVTHVVPIYAGFSLPHAILRIDL\\\n",
    "AGRDLTDYLMKILSERGYSFSTTAEREIVRDIKEKLCYVALDFEQEMQTAAQSSSIEKSY\\\n",
    "ELPDGQVITIGNERFRAPEALFHPSVLGLESAGIDQTTYNSIMKCDVDVRKELYGNIVMS\\\n",
    "GGTTMFPGIAERMQKEITALAPSSMKVKIIAPPERKYSVWIGGSILASLTTFQQMWISKQ\\\n",
    "EYDESGPSIVHHKCF\" # ACT1(375)\n",
    "\n",
    "seq = \"MSSDLAAELGFDPALKKKKKTKKVIPDDFDAAVNGKENGSGDDLFAGLKKKKKKSKSVSA\\\n",
    "DAEAEKEPTDDIAEALGELSLKKKKKKTKDSSVDAFEKELAKAGLDNVDAESKEGTPSAN\\\n",
    "SSIQQEVGLPYSELLSRFFNILRTNNPELAGDRSGPKFRIPPPVCLRDGKKTIFSNIQDI\\\n",
    "AEKLHRSPEHLIQYLFAELGTSGSVDGQKRLVIKGKFQSKQMENVLRRYILEYVTCKTCK\\\n",
    "SINTELKREQSNRLFFMVCKSCGSTRSVSSIKTGFQATVGKRRRM\" # SUI3(285)\n",
    "\n",
    "seq = \"MNFNTPQQNKTPFSFGTANNNSNTTNQNSSTGAGAFGTGQSTFGFNNSAPNNTNNANSSI\\\n",
    "TPAFGSNNTGNTAFGNSNPTSNVFGSNNSTTNTFGSNSAGTSLFGSSSAQQTKSNGTAGG\\\n",
    "NTFGSSSLFNNSTNSNTTKPAFGGLNFGGGNNTTPSSTGNANTSNNLFGATANANKPAFS\\\n",
    "FGATTNDDKKTEPDKPAFSFNSSVGNKTDAQAPTTGFSFGSQLGGNKTVNEAAKPSLSFG\\\n",
    "SGSAGANPAGASQPEPTTNEPAKPALSFGTATSDNKTTNTTPSFSFGAKSDENKAGATSK\\\n",
    "PAFSFGAKPEEKKDDNSSKPAFSFGAKSNEDKQDGTAKPAFSFGAKPAEKNNNETSKPAF\\\n",
    "SFGAKSDEKKDGDASKPAFSFGAKPDENKASATSKPAFSFGAKPEEKKDDNSSKPAFSFG\\\n",
    "AKSNEDKQDGTAKPAFSFGAKPAEKNNNETSKPAFSFGAKSDEKKDGDASKPAFSFGAKS\\\n",
    "DEKKDSDSSKPAFSFGTKSNEKKDSGSSKPAFSFGAKPDEKKNDEVSKPAFSFGAKANEK\\\n",
    "KESDESKSAFSFGSKPTGKEEGDGAKAAISFGAKPEEQKSSDTSKPAFTFGAQKDNEKKT\\\n",
    "EESSTGKSTADVKSSDSLKLNSKPVELKPVSLDNKTLDDLVTKWTNQLTESASHFEQYTK\\\n",
    "KINSWDQVLVKGGEQISQLYSDAVMAEHSQNKIDQSLQYIERQQDELENFLDNFETKTEA\\\n",
    "LLSDVVSTSSGAAANNNDQKRQQAYKTAQTLDENLNSLSSNLSSLIVEINNVSNTFNKTT\\\n",
    "NIDINNEDENIQLIKILNSHFDALRSLDDNSTSLEKQINSIKK\" # NSP1(823)\n",
    "\n",
    "\n",
    "seq = \"MSDFQKEKVEEQEQQQQQIIKIRITLTSTKVKQLENVSSNIVKNAEQHNLVKKGPVRLPT\\\n",
    "KVLKISTRKTPNGEGSKTWETYEMRIHKRYIDLEAPVQIVKRITQITIEPGVDVEVVVAS\\\n",
    "N\" # RPS20(121)\n",
    "\n",
    "seq = \"MPKLVLVRHGQSEWNEKNLFTGWVDVKLSAKGQQEAARAGELLKEKKVYPDVLYTSKLSR\\\n",
    "AIQTANIALEKADRLWIPVNRSWRLNERHYGDLQGKDKAETLKKFGEEKFNTYRRSFDVP\\\n",
    "PPPIDASSPFSQKGDERYKYVDPNVLPETESLALVIDRLLPYWQDVIAKDLLSGKTVMIA\\\n",
    "AHGNSLRGLVKHLEGISDADIAKLNIPTGIPLVFELDENLKPSKPSYYLDPEAAAAGAAA\\\n",
    "VANQGKK\" # GPM1(247)\n",
    "\n",
    "seq = \"MVKETKLYDLLGVSPSANEQELKKGYRKAALKYHPDKPTGDTEKFKEISEAFEILNDPQK\\\n",
    "REIYDQYGLEAARSGGPSFGPGGPGGAGGAGGFPGGAGGFSGGHAFSNEDAFNIFSQFFG\\\n",
    "GSSPFGGADDSGFSFSSYPSGGGAGMGGMPGGMGGMHGGMGGMPGGFRSASSSPTYPEEE\\\n",
    "TVQVNLPVSLEDLFVGKKKSFKIGRKGPHGASEKTQIDIQLKPGWKAGTKITYKNQGDYN\\\n",
    "PQTGRRKTLQFVIQEKSHPNFKRDGDDLIYTLPLSFKESLLGFSKTIQTIDGRTLPLSRV\\\n",
    "QPVQPSQTSTYPGQGMPTPKNPSQRGNLIVKYKVDYPISLNDAQKRAIDENF\" # SIS1(352)\n",
    "\n",
    "seq = \"MGKEKSHINVVVIGHVDSGKSTTTGHLIYKCGGIDKRTIEKFEKEAAELGKGSFKYAWVL\\\n",
    "DKLKAERERGITIDIALWKFETPKYQVTVIDAPGHRDFIKNMITGTSQADCAILIIAGGV\\\n",
    "GEFEAGISKDGQTREHALLAFTLGVRQLIVAVNKMDSVKWDESRFQEIVKETSNFIKKVG\\\n",
    "YNPKTVPFVPISGWNGDNMIEATTNAPWYKGWEKETKAGVVKGKTLLEAIDAIEQPSRPT\\\n",
    "DKPLRLPLQDVYKIGGIGTVPVGRVETGVIKPGMVVTFAPAGVTTEVKSVEMHHEQLEQG\\\n",
    "VPGDNVGFNVKNVSVKEIRRGNVCGDAKNDPPKGCASFNATVIVLNHPGQISAGYSPVLD\\\n",
    "CHTAHIACRFDELLEKNDRRSGKKLEDHPKFLKSGDAALVKFVPSKPMCVEAFSEYPPLG\\\n",
    "RFAVRDMRQTVAVGVIKSVDKTEKAAKVTKAAQKAAKK\" # TEF2(458)\n",
    "\n",
    "\n",
    "seq = \"MARTFFVGGNFKLNGSKQSIKEIVERLNTASIPENVEVVICPPATYLDYSVSLVKKPQVT\\\n",
    "VGAQNAYLKASGAFTGENSVDQIKDVGAKWVILGHSERRSYFHEDDKFIADKTKFALGQG\\\n",
    "VGVILCIGETLEEKKAGKTLDVVERQLNAVLEEVKDWTNVVVAYEPVWAIGTGLAATPED\\\n",
    "AQDIHASIRKFLASKLGDKAASELRILYGGSANGSNAVTFKDKADVDGFLVGGASLKPEF\\\n",
    "VDIINSRN\" # TPI1(248) !!!\n",
    "\n",
    "if (sys.argv[0][-21:] == \"ipykernel_launcher.py\"):\n",
    "    if len(seq)<= 2000:\n",
    "        print(SpotCoordinationSite({\">folder\": seq}, 'wesa'))\n",
    "    else:\n",
    "        print(\"Sequence too big for wesa: %d\"%len(seq))\n",
    "else:\n",
    "    print(\"You forgot to comment this line befor compiling.\")\n",
    "    print(\"You forgot to comment this line befor compiling.\")\n",
    "    print(\"You forgot to comment this line befor compiling.\")\n",
    "    print(\"You forgot to comment this line befor compiling.\")\n",
    "    print(\"You forgot to comment this line befor compiling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous version of the workflow code \n",
    "\n",
    "## this could retrieve only coordination sites and spacer check info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OUTPUT_FILE = \"output_yeast_structure.csv\"\n",
    "INPUT_FILE = '/home/imhof_team/Public/mauricio/workflow/yeast_type3/yeast_type3_safe2.fasta'\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(levelname)s - %(message)s')\n",
    "\n",
    "#import experiments\n",
    "import seqdhbm.SeqDHBM as SeqDHBM\n",
    "import seqdhbm.fasta as fasta\n",
    "import seqdhbm.pdbfiles as pdbfiles\n",
    "import sys, os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "def workflow(jobnum= \"J0\", fastafile=None, pdbs=[], pdbid=\"\", rawseq=\"\", mode=\"structure\"):\n",
    "    \"\"\" Runs the workflow \n",
    "    \n",
    "    Params:\n",
    "    - fasta: One fasta file\n",
    "    - pdbfiles: list of pdb filenames, they should be in the root dir\n",
    "    - pdbid: string with PDB codes (comma separated)\n",
    "    - knowstruc: boolean: we use services to obtain the structure if False\"\"\"\n",
    "    # TODO: use jobnum to organize submissions\n",
    "    # Deal with the fasta file with multiple sequences\n",
    "    seq_dict = {}\n",
    "    \n",
    "    seq_list = []\n",
    "    if fastafile:\n",
    "        \"\"\"seq_dict = fasta.fasta_to_seq(fastafile)\n",
    "        fasta.organize_sequences(seq_dict)\"\"\"\n",
    "        seq_list = fasta.fasta_to_seq2(fastafile)\n",
    "        fasta.organize_sequences2(seq_dict)\n",
    "        #logging.debug(\"fasta:\")\n",
    "        #logging.debug(seq_dict.keys())\n",
    "\n",
    "    # Deal with the pdb ids (by downloading them)\n",
    "    pdbid_dict = {} # stores the pdbfile path to each pdb id\n",
    "    if pdbid:\n",
    "        raise Exception(\"not prepared to work with they new variables\")\n",
    "        l = pdbfiles.text_to_list(pdbid)\n",
    "        pdbid_dict = pdbfiles.get_pdb_files(l)\n",
    "        #logging.debug(\"pdbid\")\n",
    "        #logging.debug(pdbid_dict)\n",
    "    \n",
    "    if rawseq:\n",
    "        seq_dict[\"Your input sequence\"] = (\"Your input sequence header\", rawseq)\n",
    "        folder = \"%s/MI/\"%jobnum\n",
    "        file = folder+\"MI1.fasta\"\n",
    "        name = \"Your input sequence\"\n",
    "        assert False, \"create the folder first\"\n",
    "        with open(file, \"w\") as f:\n",
    "            f.write(\">%s\\n\"%name)\n",
    "            lines=[rawseq[x:x+60] for x in range(0, len(rawseq), 60)]\n",
    "            f.write('\\n'.join(lines))\n",
    "        seq_list += [{\"seq\":rawseq, \n",
    "                     \"name\":name, \n",
    "                     \"folder\": folder,\n",
    "                     \"file\": file,\n",
    "                     \"submited_as\": \"Manual input\"}]\n",
    "    \n",
    "    # Arrange the pdb files (user-submitted or downloaded)\n",
    "    ## Put the structure file in folders - for docking and MD\n",
    "    ## get the primary sequence for motif search\n",
    "    for file in pdbs:\n",
    "        raise Exception(\"not prepared to work with they new variables\")\n",
    "        try:\n",
    "            folder = \".\".join(file.split(\".\")[:-1]) # remove extension\n",
    "        except:\n",
    "            folder = file\n",
    "        try:\n",
    "            os.makedirs(folder, exist_ok=True)\n",
    "            shutil.move(file, folder+\"/\"+file)\n",
    "            pdbid_dict[folder] = folder+\"/\"+file\n",
    "        except:\n",
    "            logging.error(\"Could not move file\"+ file + \"\\nSkiping it!\") # TODO: List of warnings and errors\n",
    "            # TODO: organize the files into folders\n",
    "    \n",
    "    # TODO: convert the pdbs into fasta\n",
    "    for file in pdbid_dict.values():\n",
    "        seq = pdbfiles.structure_to_fasta(file)\n",
    "        if seq:\n",
    "            seq_dict[file] = (\">header\", seq)\n",
    "    # Run the motif check\n",
    "    #logging.debug(\"*\"*30)\n",
    "    #logging.debug(seq_dict)\n",
    "    \n",
    "    #spacerinfo = {}\n",
    "    \n",
    "    hbm_result = {}\n",
    "    cnt_progress = 0\n",
    "    seq_dict = {}\n",
    "    for item in seq_list:\n",
    "        cnt_progress+=1\n",
    "        try:\n",
    "            coordsites = SeqDHBM.SpotCoordinationSite({\">\"+item[\"name\"]: item[\"seq\"]}, mode)\n",
    "            for fold, coordsite in coordsites.items():\n",
    "                # TODO: Handle what is to be done with the coordination sites\n",
    "                # Output? Save in our user output?\n",
    "                hbm_result[fold[1:]] = coordsite\n",
    "                item[\"result\"] = coordsite[\"result\"]\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(\"****\")\n",
    "            logging.error(\"%s %s\"%(item[\"name\"], header))\n",
    "            logging.error(e)\n",
    "            logging.error(type(e))\n",
    "            logging.error(e.args)\n",
    "            logging.error(\"****\")\n",
    "        finally:\n",
    "            logging.debug(\"Got the results for %s\"%item[\"name\"])\n",
    "            logging.debug(\"%d out of %d complete\"%(cnt_progress, len(seq_dict)))\n",
    "\n",
    "    return seq_list\n",
    "\n",
    "    for folder, (header, seq) in seq_dict.items():\n",
    "        \"\"\"fo = \"Saved_run/IL-1A(271)/IL-1A(271).fasta\"\n",
    "    \n",
    "        SeqDHBM.ReadFasta(fo)\"\"\"\n",
    "        #print(folder, \"$\", seq)\n",
    "        cnt_progress+=1\n",
    "        try:\n",
    "            coordsites = SeqDHBM.SpotCoordinationSite({\">\"+folder: seq}, mode)\n",
    "            for fold, coordsite in coordsites.items():\n",
    "                # TODO: Handle what is to be done with the coordination sites\n",
    "                # Output? Save in our user output?\n",
    "                hbm_result[fold[1:]] = coordsite\n",
    "        except Exception as e:\n",
    "            logging.error(\"****\")\n",
    "            logging.error(\"%s %s\"%(folder, header))\n",
    "            logging.error(e)\n",
    "            logging.error(type(e))\n",
    "            logging.error(e.args)\n",
    "            logging.error(\"****\")\n",
    "        finally:\n",
    "            logging.debug(\"Got the results for %s\"%folder)\n",
    "            logging.debug(\"%d out of %d complete\"%(cnt_progress, len(seq_dict)))\n",
    "    if hbm_result:\n",
    "        print(\"*\"*60)\n",
    "        print(\"Results for the HBM analysis\")\n",
    "        \n",
    "    \"\"\"with open(OUTPUT_FILE, \"w\") as f:\n",
    "        f.write(\"Name\\tCoordinating residue\\tSpacer > 2\\n\")\n",
    "        for fold, sites in hbm_result.items():\n",
    "            print(\"Analysis of the sequence %s\"%fold[1:])\n",
    "            for pos, spac in sites.items():\n",
    "                print(\"%s - %s\"%(str.rjust(pos,6), spac))\n",
    "                f.write(\"%s\\t%s\\t%s\\n\"%(fold, pos, spac))\n",
    "                \"\"\"; # Maybe i don't need that csv output\n",
    "    return hbm_result\n",
    "\n",
    "\n",
    "if (__name__ == \"__main__\"):\n",
    "\n",
    "    fastafile = ''\n",
    "    mode = \"\"\n",
    "    if sys.argv[0].endswith(\"ipykernel_launcher.py\"):\n",
    "        fastafile = INPUT_FILE\n",
    "        mode = \"wesa\"\n",
    "        scriptname = \"workflow\" # TODO: Will this be the final name?\n",
    "    else:\n",
    "        scriptname = os.path.basename(__file__)\n",
    "    pdbids = \"\"# \"1S0L,1L2H,1I1B,1HIB,1I8H\"\n",
    "    pdbs=[]\n",
    "    \n",
    "    for params in sys.argv:\n",
    "        if params.startswith(\"-pdbid=\"):\n",
    "            pdbids = params[7:]\n",
    "        elif params.startswith(\"-fasta=\"):\n",
    "            fastafile = params[7:]\n",
    "        elif params.startswith(\"-pdbfiles=\"):\n",
    "            # param pdbid must be formatted as list\n",
    "            pdbs = eval(params[10:])\n",
    "        elif params.startswith(\"-mode=\"):\n",
    "            # param pdbid must be formatted as list\n",
    "            mode = params[6:].lower()\n",
    "        elif params.startswith(\"-help\"):\n",
    "            print(\"Usage Help\")\n",
    "            print(\"call by using 'python %s -mode=<mode> -fasta=<fastafile> -pdbid=<pdb_id> -pdbfiles=<pdb_files>'\"%(scriptname))\n",
    "            print(\"<mode> is mandatory and accepts:\")\n",
    "            print(\"-mode=structure: if structure is known (default)\")\n",
    "            print(\"-mode=wesa: to use our services to PREDICT surface accessibility\")\n",
    "            print(\"<fastafile> is the full path of a fasta file with one or more sequences\")\n",
    "            print(\"<pdb_id> must contain the PDB ids, separated by commas.\")\n",
    "            print(\"<pdb_files> PDB files with .ent or .pdb format\")\n",
    "    \n",
    "    assert mode in [\"structure\", \"wesa\"], (\"Mode not detected!\\n\"\n",
    "    \"Use 'python %s' for help on using the application\\n\")\n",
    "            \n",
    "    workflow(jobnum=0, fastafile=fastafile, pdbs=pdbs, pdbid=pdbids, mode=mode)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
